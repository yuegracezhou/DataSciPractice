{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注：把开学他给的文件包里的Utils.py 和这个notebook放到一个目录底下从而方便improt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from Utils import timeout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目标分布 f(x) 是目标分布的概率密度函数（PDF, Probability Density Function），而问题中的F(x) 是一个累积分布函数（CDF, Cumulative Distribution Function）,因此需要F(x)对x求导得出f(x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1\n",
    "@timeout(seconds=10)\n",
    "def problem1_inversion(n_samples=1):\n",
    "# Distribution from part 1\n",
    "# write the code in this function to produce samples from the distribution in the assignment\n",
    "# Make sure you choose a good sampling distribution to avoid unnecessary rejections\n",
    "# Return a numpy array of length n_samples\n",
    "    \"\"\"\n",
    "    使用拒绝采样法从给定分布生成样本。\n",
    "    \"\"\"\n",
    "    def target_pdf(x):\n",
    "        \"\"\"\n",
    "        目标概率密度函数 p(x)。\n",
    "        也可以用 lambda 表达式来写\n",
    "        \"\"\"\n",
    "        return 2*x*np.exp(x*x)/(np.e-1)\n",
    "        # 返回 p(x)  # 给定的概率密度函数\n",
    "\n",
    "    def proposal_pdf(x):\n",
    "        \"\"\"\n",
    "        提议分布 q(x)：均匀分布。\n",
    "        我们通常在给定区间上使用均匀分布，\n",
    "        或者选择某种 Beta 分布使得更容易被接受\n",
    "        （实际上，我们选择具有厚尾的分布）\n",
    "        \"\"\"\n",
    "        return 1  # 在 x 范围内的均匀分布\n",
    "\n",
    "    # 拒绝采样的参数\n",
    "    M = 2*np.e/(np.e-1)  # 缩放常数，基于最大比值 p(x) / q(x) 选择，M 越接近该比值，接受的概率越大\n",
    "    samples = []\n",
    "    count = 0  # 统计总迭代次数，用于效率检查\n",
    "\n",
    "    while len(samples) < n_samples:\n",
    "        x = np.random.uniform(0, 1)  # 从均匀分布中采样\n",
    "        u = np.random.uniform(0, M * proposal_pdf(x))  # 用于接受的均匀随机数\n",
    "\n",
    "        if u <= target_pdf(x):  # 是否接受样本\n",
    "            samples.append(x)\n",
    "        count += 1\n",
    "\n",
    "    return np.array(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Part 1-参考\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 定义目标分布的密度函数 f(x)\n",
    "def target_density(x):\n",
    "    if 0 < x < 1:\n",
    "        return (2 * x * np.exp(x**2)) / (np.exp(1) - 1)\n",
    "    return 0\n",
    "\n",
    "# 定义辅助分布的密度函数 g(x) (均匀分布)\n",
    "def proposal_density(x):\n",
    "    return 1  # 均匀分布在 [0, 1] 的密度为 1\n",
    "\n",
    "# 计算常数 c (f(x) 的最大值)\n",
    "def compute_c():\n",
    "    x_values = np.linspace(0, 1, 1000)\n",
    "    f_values = [target_density(x) for x in x_values]\n",
    "    return max(f_values)\n",
    "\n",
    "# 拒绝采样算法\n",
    "def rejection_sampling(num_samples):\n",
    "    c = compute_c()  # 确定常数 c\n",
    "    samples = []\n",
    "\n",
    "    while len(samples) < num_samples:\n",
    "        # 从均匀分布中生成候选样本,辅助分布的定义域必须完全覆盖目标分布的定义域\n",
    "        x = np.random.uniform(0, 1)\n",
    "        u = np.random.uniform(0, 1)\n",
    "\n",
    "        # 计算目标分布的密度值\n",
    "        f_x = target_density(x)\n",
    "\n",
    "        # 判断是否接受样本\n",
    "        if u <= f_x / c:\n",
    "            samples.append(x)\n",
    "\n",
    "    return samples\n",
    "\n",
    "# 生成样本\n",
    "num_samples = 100000\n",
    "samples = rejection_sampling(num_samples)\n",
    "\n",
    "# 绘制生成的样本分布和目标分布\n",
    "x = np.linspace(0, 1, 1000)\n",
    "y = [target_density(xi) for xi in x]\n",
    "\n",
    "plt.hist(samples, bins=50, density=True, alpha=0.6, label='Sampled Distribution')\n",
    "plt.plot(x, y, label='Target Density', color='red')\n",
    "plt.legend()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Rejection Sampling Results')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2\n",
    "problem1_samples = problem1_inversion(n_samples=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theory for part 3:\n",
    "$\\mathbb{E}[g(x)]=\\int_D sin(x)p(x)dx$, if $x \\in D$ and x's probability density fuction is $p(x) $\n",
    "So we use $\\frac{1}{n}\\sum_i sin(x_i)$ to estimate$\\mathbb{E}[g(x)]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem1_integral: 0.6523983653933686\n"
     ]
    }
   ],
   "source": [
    "# Part 3\n",
    "problem1_integral = sum([np.sin(x) for x in problem1_samples])/len(problem1_samples)\n",
    "print(\"problem1_integral:\", problem1_integral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3-参考\n",
    "import numpy as np\n",
    "\n",
    "# 定义 g(x) = sin(x)\n",
    "def g(x):\n",
    "    return np.sin(x)\n",
    "\n",
    "# 从 problem1_samples 中近似计算积分\n",
    "def monte_carlo_integration(samples):\n",
    "    # 计算 g(x) 的值\n",
    "    g_values = g(np.array(samples))\n",
    "    \n",
    "    # 求平均值，近似积分\n",
    "    integral = np.mean(g_values)\n",
    "    return integral\n",
    "\n",
    "# 假设前面生成了 100000 个样本 problem1_samples\n",
    "# 从均匀分布 [0, 1] 中生成一些样本作为测试（实际中应替换为你的采样结果）\n",
    "problem1_samples =rejection_sampling(num_samples)\n",
    "\n",
    "# 计算积分\n",
    "problem1_integral = monte_carlo_integration(problem1_samples)\n",
    "print(\"近似积分值为:\", problem1_integral)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epsilon: 0.01142803019919356\n",
      "95% confidence interval for E[Y]: (0.640970335194175, 0.6638263955925622)\n"
     ]
    }
   ],
   "source": [
    "# Part 4\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# 假设我们已经有 n 个样本的 Y 值\n",
    "n = 10000  # 样本数量\n",
    "Y_mean = problem1_integral\n",
    "\n",
    "# Y 的范围 [a, b], 即 E(sin(X))的取值范围\n",
    "a = 0  # 最小值发生在 X = 0\n",
    "b = np.sin(1)  # 最大值发生在 X = 1\n",
    "\n",
    "# Hoeffding's inequality 参数\n",
    "delta = 0.05  # 1 - 置信水平\n",
    "epsilon = math.sqrt(((b - a)**2 * math.log(2 / delta)) / (2 * n))\n",
    "\n",
    "# 计算置信区间\n",
    "problem1_interval = (Y_mean - epsilon, Y_mean + epsilon)\n",
    "\n",
    "print(f\"95% confidence interval for E[Y]: {problem1_interval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed c: 55.971202630989595\n",
      "Iterations: 1000, Samples: 20\n",
      "Iterations: 2000, Samples: 38\n",
      "Iterations: 3000, Samples: 53\n",
      "Iterations: 4000, Samples: 70\n",
      "Iterations: 5000, Samples: 89\n",
      "Iterations: 6000, Samples: 103\n",
      "Iterations: 7000, Samples: 121\n",
      "Iterations: 8000, Samples: 143\n",
      "Iterations: 9000, Samples: 156\n",
      "Iterations: 10000, Samples: 171\n",
      "Iterations: 11000, Samples: 182\n",
      "Iterations: 12000, Samples: 193\n",
      "Iterations: 13000, Samples: 207\n",
      "Iterations: 14000, Samples: 227\n",
      "Iterations: 15000, Samples: 245\n",
      "Iterations: 16000, Samples: 268\n",
      "Iterations: 17000, Samples: 282\n",
      "Iterations: 18000, Samples: 302\n",
      "Iterations: 19000, Samples: 314\n",
      "Iterations: 20000, Samples: 331\n",
      "Iterations: 21000, Samples: 349\n",
      "Iterations: 22000, Samples: 362\n",
      "Iterations: 23000, Samples: 379\n",
      "Iterations: 24000, Samples: 394\n",
      "Iterations: 25000, Samples: 416\n",
      "Iterations: 26000, Samples: 428\n",
      "Iterations: 27000, Samples: 438\n",
      "Iterations: 28000, Samples: 458\n",
      "Iterations: 29000, Samples: 477\n",
      "Iterations: 30000, Samples: 495\n",
      "Iterations: 31000, Samples: 514\n",
      "Iterations: 32000, Samples: 532\n",
      "Iterations: 33000, Samples: 544\n",
      "Iterations: 34000, Samples: 558\n",
      "Iterations: 35000, Samples: 576\n",
      "Iterations: 36000, Samples: 593\n",
      "Iterations: 37000, Samples: 608\n",
      "Iterations: 38000, Samples: 628\n",
      "Iterations: 39000, Samples: 647\n",
      "Iterations: 40000, Samples: 660\n",
      "Iterations: 41000, Samples: 679\n",
      "Iterations: 42000, Samples: 691\n",
      "Iterations: 43000, Samples: 706\n",
      "Iterations: 44000, Samples: 720\n",
      "Iterations: 45000, Samples: 738\n",
      "Iterations: 46000, Samples: 755\n",
      "Iterations: 47000, Samples: 772\n",
      "Iterations: 48000, Samples: 792\n",
      "Iterations: 49000, Samples: 809\n",
      "Iterations: 50000, Samples: 823\n",
      "Iterations: 51000, Samples: 836\n",
      "Iterations: 52000, Samples: 849\n",
      "Iterations: 53000, Samples: 869\n",
      "Iterations: 54000, Samples: 884\n",
      "Iterations: 55000, Samples: 895\n",
      "Iterations: 56000, Samples: 912\n",
      "Iterations: 57000, Samples: 933\n",
      "Iterations: 58000, Samples: 953\n",
      "Iterations: 59000, Samples: 972\n",
      "Iterations: 60000, Samples: 987\n",
      "Iterations: 61000, Samples: 999\n",
      "Iterations: 62000, Samples: 1014\n",
      "Iterations: 63000, Samples: 1026\n",
      "Iterations: 64000, Samples: 1043\n",
      "Iterations: 65000, Samples: 1062\n",
      "Iterations: 66000, Samples: 1080\n",
      "Iterations: 67000, Samples: 1103\n",
      "Iterations: 68000, Samples: 1115\n",
      "Iterations: 69000, Samples: 1136\n",
      "Iterations: 70000, Samples: 1152\n",
      "Iterations: 71000, Samples: 1171\n",
      "Iterations: 72000, Samples: 1184\n",
      "Iterations: 73000, Samples: 1196\n",
      "Iterations: 74000, Samples: 1220\n",
      "Iterations: 75000, Samples: 1239\n",
      "Iterations: 76000, Samples: 1261\n",
      "Iterations: 77000, Samples: 1276\n",
      "Iterations: 78000, Samples: 1290\n",
      "Iterations: 79000, Samples: 1301\n",
      "Iterations: 80000, Samples: 1323\n",
      "Iterations: 81000, Samples: 1340\n",
      "Iterations: 82000, Samples: 1361\n",
      "Iterations: 83000, Samples: 1386\n",
      "Iterations: 84000, Samples: 1398\n",
      "Iterations: 85000, Samples: 1421\n",
      "Iterations: 86000, Samples: 1439\n",
      "Iterations: 87000, Samples: 1458\n",
      "Iterations: 88000, Samples: 1471\n",
      "Iterations: 89000, Samples: 1488\n",
      "Iterations: 90000, Samples: 1510\n",
      "Iterations: 91000, Samples: 1530\n",
      "Iterations: 92000, Samples: 1548\n",
      "Iterations: 93000, Samples: 1570\n",
      "Iterations: 94000, Samples: 1585\n",
      "Iterations: 95000, Samples: 1605\n",
      "Iterations: 96000, Samples: 1625\n",
      "Iterations: 97000, Samples: 1638\n",
      "Iterations: 98000, Samples: 1656\n",
      "Iterations: 99000, Samples: 1672\n",
      "Iterations: 100000, Samples: 1694\n",
      "Iterations: 101000, Samples: 1720\n",
      "Iterations: 102000, Samples: 1733\n",
      "Iterations: 103000, Samples: 1748\n",
      "Iterations: 104000, Samples: 1764\n",
      "Iterations: 105000, Samples: 1786\n",
      "Iterations: 106000, Samples: 1796\n",
      "Iterations: 107000, Samples: 1815\n",
      "Iterations: 108000, Samples: 1838\n",
      "Iterations: 109000, Samples: 1860\n",
      "Iterations: 110000, Samples: 1876\n",
      "Iterations: 111000, Samples: 1891\n",
      "Iterations: 112000, Samples: 1913\n",
      "Iterations: 113000, Samples: 1931\n",
      "Iterations: 114000, Samples: 1952\n",
      "Iterations: 115000, Samples: 1974\n",
      "Iterations: 116000, Samples: 1988\n",
      "Iterations: 117000, Samples: 2004\n",
      "Iterations: 118000, Samples: 2016\n",
      "Iterations: 119000, Samples: 2034\n",
      "Iterations: 120000, Samples: 2058\n",
      "Iterations: 121000, Samples: 2076\n",
      "Iterations: 122000, Samples: 2092\n",
      "Iterations: 123000, Samples: 2112\n",
      "Iterations: 124000, Samples: 2126\n",
      "Iterations: 125000, Samples: 2145\n",
      "Iterations: 126000, Samples: 2166\n",
      "Iterations: 127000, Samples: 2187\n",
      "Iterations: 128000, Samples: 2203\n",
      "Iterations: 129000, Samples: 2229\n",
      "Iterations: 130000, Samples: 2245\n",
      "Iterations: 131000, Samples: 2257\n",
      "Iterations: 132000, Samples: 2274\n",
      "Iterations: 133000, Samples: 2292\n",
      "Iterations: 134000, Samples: 2312\n",
      "Iterations: 135000, Samples: 2324\n",
      "Iterations: 136000, Samples: 2339\n",
      "Iterations: 137000, Samples: 2351\n",
      "Iterations: 138000, Samples: 2367\n",
      "Iterations: 139000, Samples: 2388\n",
      "Iterations: 140000, Samples: 2407\n",
      "Iterations: 141000, Samples: 2422\n",
      "Iterations: 142000, Samples: 2438\n",
      "Iterations: 143000, Samples: 2461\n",
      "Iterations: 144000, Samples: 2477\n",
      "Iterations: 145000, Samples: 2504\n",
      "Iterations: 146000, Samples: 2528\n",
      "Iterations: 147000, Samples: 2551\n",
      "Iterations: 148000, Samples: 2574\n",
      "Iterations: 149000, Samples: 2593\n",
      "Iterations: 150000, Samples: 2612\n",
      "Iterations: 151000, Samples: 2634\n",
      "Iterations: 152000, Samples: 2650\n",
      "Iterations: 153000, Samples: 2669\n",
      "Iterations: 154000, Samples: 2683\n",
      "Iterations: 155000, Samples: 2703\n",
      "Iterations: 156000, Samples: 2721\n",
      "Iterations: 157000, Samples: 2742\n",
      "Iterations: 158000, Samples: 2764\n",
      "Iterations: 159000, Samples: 2772\n",
      "Iterations: 160000, Samples: 2790\n",
      "Iterations: 161000, Samples: 2812\n",
      "Iterations: 162000, Samples: 2828\n",
      "Iterations: 163000, Samples: 2844\n",
      "Iterations: 164000, Samples: 2861\n",
      "Iterations: 165000, Samples: 2874\n",
      "Iterations: 166000, Samples: 2893\n",
      "Iterations: 167000, Samples: 2915\n",
      "Iterations: 168000, Samples: 2932\n",
      "Iterations: 169000, Samples: 2951\n",
      "Iterations: 170000, Samples: 2963\n",
      "Iterations: 171000, Samples: 2989\n",
      "Iterations: 172000, Samples: 3005\n",
      "Iterations: 173000, Samples: 3025\n",
      "Iterations: 174000, Samples: 3043\n",
      "Iterations: 175000, Samples: 3059\n",
      "Iterations: 176000, Samples: 3080\n",
      "Iterations: 177000, Samples: 3096\n",
      "Iterations: 178000, Samples: 3109\n",
      "Iterations: 179000, Samples: 3133\n",
      "Iterations: 180000, Samples: 3144\n",
      "Iterations: 181000, Samples: 3157\n",
      "Iterations: 182000, Samples: 3175\n",
      "Iterations: 183000, Samples: 3188\n",
      "Iterations: 184000, Samples: 3204\n",
      "Iterations: 185000, Samples: 3219\n",
      "Iterations: 186000, Samples: 3239\n",
      "Iterations: 187000, Samples: 3254\n",
      "Iterations: 188000, Samples: 3266\n",
      "Iterations: 189000, Samples: 3279\n",
      "Iterations: 190000, Samples: 3302\n",
      "Iterations: 191000, Samples: 3324\n",
      "Iterations: 192000, Samples: 3342\n",
      "Iterations: 193000, Samples: 3361\n",
      "Iterations: 194000, Samples: 3377\n",
      "Iterations: 195000, Samples: 3394\n",
      "Iterations: 196000, Samples: 3411\n",
      "Iterations: 197000, Samples: 3422\n",
      "Iterations: 198000, Samples: 3435\n",
      "Iterations: 199000, Samples: 3449\n",
      "Iterations: 200000, Samples: 3471\n",
      "Iterations: 201000, Samples: 3490\n",
      "Iterations: 202000, Samples: 3509\n",
      "Iterations: 203000, Samples: 3528\n",
      "Iterations: 204000, Samples: 3544\n",
      "Iterations: 205000, Samples: 3560\n",
      "Iterations: 206000, Samples: 3578\n",
      "Iterations: 207000, Samples: 3595\n",
      "Iterations: 208000, Samples: 3619\n",
      "Iterations: 209000, Samples: 3630\n",
      "Iterations: 210000, Samples: 3646\n",
      "Iterations: 211000, Samples: 3662\n",
      "Iterations: 212000, Samples: 3684\n",
      "Iterations: 213000, Samples: 3706\n",
      "Iterations: 214000, Samples: 3723\n",
      "Iterations: 215000, Samples: 3743\n",
      "Iterations: 216000, Samples: 3756\n",
      "Iterations: 217000, Samples: 3764\n",
      "Iterations: 218000, Samples: 3774\n",
      "Iterations: 219000, Samples: 3788\n",
      "Iterations: 220000, Samples: 3801\n",
      "Iterations: 221000, Samples: 3820\n",
      "Iterations: 222000, Samples: 3837\n",
      "Iterations: 223000, Samples: 3850\n",
      "Iterations: 224000, Samples: 3867\n",
      "Iterations: 225000, Samples: 3882\n",
      "Iterations: 226000, Samples: 3896\n",
      "Iterations: 227000, Samples: 3912\n",
      "Iterations: 228000, Samples: 3934\n",
      "Iterations: 229000, Samples: 3962\n",
      "Iterations: 230000, Samples: 3978\n",
      "Iterations: 231000, Samples: 3994\n",
      "Iterations: 232000, Samples: 4008\n",
      "Iterations: 233000, Samples: 4030\n",
      "Iterations: 234000, Samples: 4056\n",
      "Iterations: 235000, Samples: 4073\n",
      "Iterations: 236000, Samples: 4093\n",
      "Iterations: 237000, Samples: 4105\n",
      "Iterations: 238000, Samples: 4125\n",
      "Iterations: 239000, Samples: 4149\n",
      "Iterations: 240000, Samples: 4166\n",
      "Iterations: 241000, Samples: 4183\n",
      "Iterations: 242000, Samples: 4202\n",
      "Iterations: 243000, Samples: 4221\n",
      "Iterations: 244000, Samples: 4239\n",
      "Iterations: 245000, Samples: 4250\n",
      "Iterations: 246000, Samples: 4266\n",
      "Iterations: 247000, Samples: 4279\n",
      "Iterations: 248000, Samples: 4294\n",
      "Iterations: 249000, Samples: 4314\n",
      "Iterations: 250000, Samples: 4335\n",
      "Iterations: 251000, Samples: 4356\n",
      "Iterations: 252000, Samples: 4371\n",
      "Iterations: 253000, Samples: 4387\n",
      "Iterations: 254000, Samples: 4398\n",
      "Iterations: 255000, Samples: 4414\n",
      "Iterations: 256000, Samples: 4433\n",
      "Iterations: 257000, Samples: 4443\n",
      "Iterations: 258000, Samples: 4459\n",
      "Iterations: 259000, Samples: 4482\n",
      "Iterations: 260000, Samples: 4501\n",
      "Iterations: 261000, Samples: 4519\n",
      "Iterations: 262000, Samples: 4536\n",
      "Iterations: 263000, Samples: 4548\n",
      "Iterations: 264000, Samples: 4561\n",
      "Iterations: 265000, Samples: 4571\n",
      "Iterations: 266000, Samples: 4596\n",
      "Iterations: 267000, Samples: 4608\n",
      "Iterations: 268000, Samples: 4630\n",
      "Iterations: 269000, Samples: 4645\n",
      "Iterations: 270000, Samples: 4665\n",
      "Iterations: 271000, Samples: 4678\n",
      "Iterations: 272000, Samples: 4691\n",
      "Iterations: 273000, Samples: 4709\n",
      "Iterations: 274000, Samples: 4735\n",
      "Iterations: 275000, Samples: 4758\n",
      "Iterations: 276000, Samples: 4776\n",
      "Iterations: 277000, Samples: 4793\n",
      "Iterations: 278000, Samples: 4801\n",
      "Iterations: 279000, Samples: 4819\n",
      "Iterations: 280000, Samples: 4837\n",
      "Iterations: 281000, Samples: 4860\n",
      "Iterations: 282000, Samples: 4880\n",
      "Iterations: 283000, Samples: 4891\n",
      "Iterations: 284000, Samples: 4914\n",
      "Iterations: 285000, Samples: 4933\n",
      "Iterations: 286000, Samples: 4947\n",
      "Iterations: 287000, Samples: 4967\n",
      "Iterations: 288000, Samples: 4977\n",
      "Iterations: 289000, Samples: 4992\n",
      "Iterations: 290000, Samples: 5010\n",
      "Iterations: 291000, Samples: 5030\n",
      "Iterations: 292000, Samples: 5046\n",
      "Iterations: 293000, Samples: 5065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 294000, Samples: 5081\n",
      "Iterations: 295000, Samples: 5108\n",
      "Iterations: 296000, Samples: 5129\n",
      "Iterations: 297000, Samples: 5150\n",
      "Iterations: 298000, Samples: 5163\n",
      "Iterations: 299000, Samples: 5178\n",
      "Iterations: 300000, Samples: 5198\n",
      "Iterations: 301000, Samples: 5220\n",
      "Iterations: 302000, Samples: 5236\n",
      "Iterations: 303000, Samples: 5253\n",
      "Iterations: 304000, Samples: 5274\n",
      "Iterations: 305000, Samples: 5295\n",
      "Iterations: 306000, Samples: 5315\n",
      "Iterations: 307000, Samples: 5323\n",
      "Iterations: 308000, Samples: 5339\n",
      "Iterations: 309000, Samples: 5365\n",
      "Iterations: 310000, Samples: 5382\n",
      "Iterations: 311000, Samples: 5397\n",
      "Iterations: 312000, Samples: 5419\n",
      "Iterations: 313000, Samples: 5438\n",
      "Iterations: 314000, Samples: 5455\n",
      "Iterations: 315000, Samples: 5469\n",
      "Iterations: 316000, Samples: 5484\n",
      "Iterations: 317000, Samples: 5501\n",
      "Iterations: 318000, Samples: 5520\n",
      "Iterations: 319000, Samples: 5535\n",
      "Iterations: 320000, Samples: 5546\n",
      "Iterations: 321000, Samples: 5566\n",
      "Iterations: 322000, Samples: 5577\n",
      "Iterations: 323000, Samples: 5603\n",
      "Iterations: 324000, Samples: 5619\n",
      "Iterations: 325000, Samples: 5629\n",
      "Iterations: 326000, Samples: 5643\n",
      "Iterations: 327000, Samples: 5671\n",
      "Iterations: 328000, Samples: 5689\n",
      "Iterations: 329000, Samples: 5706\n",
      "Iterations: 330000, Samples: 5734\n",
      "Iterations: 331000, Samples: 5757\n",
      "Iterations: 332000, Samples: 5778\n",
      "Iterations: 333000, Samples: 5789\n",
      "Iterations: 334000, Samples: 5803\n",
      "Iterations: 335000, Samples: 5823\n",
      "Iterations: 336000, Samples: 5848\n",
      "Iterations: 337000, Samples: 5860\n",
      "Iterations: 338000, Samples: 5885\n",
      "Iterations: 339000, Samples: 5900\n",
      "Iterations: 340000, Samples: 5918\n",
      "Iterations: 341000, Samples: 5936\n",
      "Iterations: 342000, Samples: 5951\n",
      "Iterations: 343000, Samples: 5975\n",
      "Iterations: 344000, Samples: 5992\n",
      "Iterations: 345000, Samples: 6006\n",
      "Iterations: 346000, Samples: 6025\n",
      "Iterations: 347000, Samples: 6047\n",
      "Iterations: 348000, Samples: 6060\n",
      "Iterations: 349000, Samples: 6080\n",
      "Iterations: 350000, Samples: 6099\n",
      "Iterations: 351000, Samples: 6114\n",
      "Iterations: 352000, Samples: 6126\n",
      "Iterations: 353000, Samples: 6148\n",
      "Iterations: 354000, Samples: 6164\n",
      "Iterations: 355000, Samples: 6188\n",
      "Iterations: 356000, Samples: 6209\n",
      "Iterations: 357000, Samples: 6224\n",
      "Iterations: 358000, Samples: 6239\n",
      "Iterations: 359000, Samples: 6251\n",
      "Iterations: 360000, Samples: 6261\n",
      "Iterations: 361000, Samples: 6281\n",
      "Iterations: 362000, Samples: 6299\n",
      "Iterations: 363000, Samples: 6318\n",
      "Iterations: 364000, Samples: 6347\n",
      "Iterations: 365000, Samples: 6360\n",
      "Iterations: 366000, Samples: 6383\n",
      "Iterations: 367000, Samples: 6400\n",
      "Iterations: 368000, Samples: 6416\n",
      "Iterations: 369000, Samples: 6433\n",
      "Iterations: 370000, Samples: 6452\n",
      "Iterations: 371000, Samples: 6481\n",
      "Iterations: 372000, Samples: 6497\n",
      "Iterations: 373000, Samples: 6517\n",
      "Iterations: 374000, Samples: 6538\n",
      "Iterations: 375000, Samples: 6552\n",
      "Iterations: 376000, Samples: 6565\n",
      "Iterations: 377000, Samples: 6584\n",
      "Iterations: 378000, Samples: 6602\n",
      "Iterations: 379000, Samples: 6624\n",
      "Iterations: 380000, Samples: 6638\n",
      "Iterations: 381000, Samples: 6650\n",
      "Iterations: 382000, Samples: 6665\n",
      "Iterations: 383000, Samples: 6678\n",
      "Iterations: 384000, Samples: 6701\n",
      "Iterations: 385000, Samples: 6715\n",
      "Iterations: 386000, Samples: 6734\n",
      "Iterations: 387000, Samples: 6751\n",
      "Iterations: 388000, Samples: 6771\n",
      "Iterations: 389000, Samples: 6789\n",
      "Iterations: 390000, Samples: 6814\n",
      "Iterations: 391000, Samples: 6827\n",
      "Iterations: 392000, Samples: 6845\n",
      "Iterations: 393000, Samples: 6861\n",
      "Iterations: 394000, Samples: 6874\n",
      "Iterations: 395000, Samples: 6897\n",
      "Iterations: 396000, Samples: 6914\n",
      "Iterations: 397000, Samples: 6937\n",
      "Iterations: 398000, Samples: 6950\n",
      "Iterations: 399000, Samples: 6964\n",
      "Iterations: 400000, Samples: 6983\n",
      "Iterations: 401000, Samples: 7003\n",
      "Iterations: 402000, Samples: 7019\n",
      "Iterations: 403000, Samples: 7033\n",
      "Iterations: 404000, Samples: 7057\n",
      "Iterations: 405000, Samples: 7078\n",
      "Iterations: 406000, Samples: 7091\n",
      "Iterations: 407000, Samples: 7104\n",
      "Iterations: 408000, Samples: 7116\n",
      "Iterations: 409000, Samples: 7130\n",
      "Iterations: 410000, Samples: 7147\n",
      "Iterations: 411000, Samples: 7168\n",
      "Iterations: 412000, Samples: 7188\n",
      "Iterations: 413000, Samples: 7207\n",
      "Iterations: 414000, Samples: 7224\n",
      "Iterations: 415000, Samples: 7246\n",
      "Iterations: 416000, Samples: 7259\n",
      "Iterations: 417000, Samples: 7280\n",
      "Iterations: 418000, Samples: 7300\n",
      "Iterations: 419000, Samples: 7319\n",
      "Iterations: 420000, Samples: 7332\n",
      "Iterations: 421000, Samples: 7348\n",
      "Iterations: 422000, Samples: 7366\n",
      "Iterations: 423000, Samples: 7386\n",
      "Iterations: 424000, Samples: 7402\n",
      "Iterations: 425000, Samples: 7416\n",
      "Iterations: 426000, Samples: 7433\n",
      "Iterations: 427000, Samples: 7452\n",
      "Iterations: 428000, Samples: 7467\n",
      "Iterations: 429000, Samples: 7483\n",
      "Iterations: 430000, Samples: 7502\n",
      "Iterations: 431000, Samples: 7517\n",
      "Iterations: 432000, Samples: 7541\n",
      "Iterations: 433000, Samples: 7556\n",
      "Iterations: 434000, Samples: 7573\n",
      "Iterations: 435000, Samples: 7581\n",
      "Iterations: 436000, Samples: 7601\n",
      "Iterations: 437000, Samples: 7619\n",
      "Iterations: 438000, Samples: 7640\n",
      "Iterations: 439000, Samples: 7656\n",
      "Iterations: 440000, Samples: 7675\n",
      "Iterations: 441000, Samples: 7694\n",
      "Iterations: 442000, Samples: 7714\n",
      "Iterations: 443000, Samples: 7730\n",
      "Iterations: 444000, Samples: 7748\n",
      "Iterations: 445000, Samples: 7766\n",
      "Iterations: 446000, Samples: 7788\n",
      "Iterations: 447000, Samples: 7806\n",
      "Iterations: 448000, Samples: 7822\n",
      "Iterations: 449000, Samples: 7833\n",
      "Iterations: 450000, Samples: 7848\n",
      "Iterations: 451000, Samples: 7868\n",
      "Iterations: 452000, Samples: 7885\n",
      "Iterations: 453000, Samples: 7903\n",
      "Iterations: 454000, Samples: 7924\n",
      "Iterations: 455000, Samples: 7943\n",
      "Iterations: 456000, Samples: 7957\n",
      "Iterations: 457000, Samples: 7971\n",
      "Iterations: 458000, Samples: 7995\n",
      "Iterations: 459000, Samples: 8009\n",
      "Iterations: 460000, Samples: 8028\n",
      "Iterations: 461000, Samples: 8043\n",
      "Iterations: 462000, Samples: 8062\n",
      "Iterations: 463000, Samples: 8084\n",
      "Iterations: 464000, Samples: 8105\n",
      "Iterations: 465000, Samples: 8121\n",
      "Iterations: 466000, Samples: 8134\n",
      "Iterations: 467000, Samples: 8155\n",
      "Iterations: 468000, Samples: 8165\n",
      "Iterations: 469000, Samples: 8176\n",
      "Iterations: 470000, Samples: 8202\n",
      "Iterations: 471000, Samples: 8223\n",
      "Iterations: 472000, Samples: 8233\n",
      "Iterations: 473000, Samples: 8247\n",
      "Iterations: 474000, Samples: 8260\n",
      "Iterations: 475000, Samples: 8278\n",
      "Iterations: 476000, Samples: 8296\n",
      "Iterations: 477000, Samples: 8316\n",
      "Iterations: 478000, Samples: 8330\n",
      "Iterations: 479000, Samples: 8343\n",
      "Iterations: 480000, Samples: 8362\n",
      "Iterations: 481000, Samples: 8375\n",
      "Iterations: 482000, Samples: 8398\n",
      "Iterations: 483000, Samples: 8418\n",
      "Iterations: 484000, Samples: 8443\n",
      "Iterations: 485000, Samples: 8457\n",
      "Iterations: 486000, Samples: 8481\n",
      "Iterations: 487000, Samples: 8498\n",
      "Iterations: 488000, Samples: 8515\n",
      "Iterations: 489000, Samples: 8534\n",
      "Iterations: 490000, Samples: 8552\n",
      "Iterations: 491000, Samples: 8572\n",
      "Iterations: 492000, Samples: 8592\n",
      "Iterations: 493000, Samples: 8609\n",
      "Iterations: 494000, Samples: 8624\n",
      "Iterations: 495000, Samples: 8647\n",
      "Iterations: 496000, Samples: 8675\n",
      "Iterations: 497000, Samples: 8691\n",
      "Iterations: 498000, Samples: 8708\n",
      "Iterations: 499000, Samples: 8727\n",
      "Iterations: 500000, Samples: 8754\n",
      "Iterations: 501000, Samples: 8775\n",
      "Iterations: 502000, Samples: 8792\n",
      "Iterations: 503000, Samples: 8805\n",
      "Iterations: 504000, Samples: 8823\n",
      "Iterations: 505000, Samples: 8842\n",
      "Iterations: 506000, Samples: 8862\n",
      "Iterations: 507000, Samples: 8888\n",
      "Iterations: 508000, Samples: 8906\n",
      "Iterations: 509000, Samples: 8935\n",
      "Iterations: 510000, Samples: 8949\n",
      "Iterations: 511000, Samples: 8959\n",
      "Iterations: 512000, Samples: 8975\n",
      "Iterations: 513000, Samples: 8996\n",
      "Iterations: 514000, Samples: 9012\n",
      "Iterations: 515000, Samples: 9033\n",
      "Iterations: 516000, Samples: 9048\n",
      "Iterations: 517000, Samples: 9060\n",
      "Iterations: 518000, Samples: 9082\n",
      "Iterations: 519000, Samples: 9100\n",
      "Iterations: 520000, Samples: 9113\n",
      "Iterations: 521000, Samples: 9122\n",
      "Iterations: 522000, Samples: 9138\n",
      "Iterations: 523000, Samples: 9156\n",
      "Iterations: 524000, Samples: 9175\n",
      "Iterations: 525000, Samples: 9186\n",
      "Iterations: 526000, Samples: 9203\n",
      "Iterations: 527000, Samples: 9217\n",
      "Iterations: 528000, Samples: 9236\n",
      "Iterations: 529000, Samples: 9253\n",
      "Iterations: 530000, Samples: 9272\n",
      "Iterations: 531000, Samples: 9289\n",
      "Iterations: 532000, Samples: 9306\n",
      "Iterations: 533000, Samples: 9324\n",
      "Iterations: 534000, Samples: 9345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations: 535000, Samples: 9370\n",
      "Iterations: 536000, Samples: 9391\n",
      "Iterations: 537000, Samples: 9411\n",
      "Iterations: 538000, Samples: 9423\n",
      "Iterations: 539000, Samples: 9447\n",
      "Iterations: 540000, Samples: 9458\n",
      "Iterations: 541000, Samples: 9470\n",
      "Iterations: 542000, Samples: 9487\n",
      "Iterations: 543000, Samples: 9500\n",
      "Iterations: 544000, Samples: 9514\n",
      "Iterations: 545000, Samples: 9537\n",
      "Iterations: 546000, Samples: 9557\n",
      "Iterations: 547000, Samples: 9577\n",
      "Iterations: 548000, Samples: 9594\n",
      "Iterations: 549000, Samples: 9610\n",
      "Iterations: 550000, Samples: 9632\n",
      "Iterations: 551000, Samples: 9647\n",
      "Iterations: 552000, Samples: 9661\n",
      "Iterations: 553000, Samples: 9680\n",
      "Iterations: 554000, Samples: 9702\n",
      "Iterations: 555000, Samples: 9720\n",
      "Iterations: 556000, Samples: 9741\n",
      "Iterations: 557000, Samples: 9758\n",
      "Iterations: 558000, Samples: 9772\n",
      "Iterations: 559000, Samples: 9788\n",
      "Iterations: 560000, Samples: 9800\n",
      "Iterations: 561000, Samples: 9818\n",
      "Iterations: 562000, Samples: 9838\n",
      "Iterations: 563000, Samples: 9867\n",
      "Iterations: 564000, Samples: 9893\n",
      "Iterations: 565000, Samples: 9907\n",
      "Iterations: 566000, Samples: 9926\n",
      "Iterations: 567000, Samples: 9938\n",
      "Iterations: 568000, Samples: 9958\n",
      "Iterations: 569000, Samples: 9975\n",
      "Iterations: 570000, Samples: 9991\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 定义目标分布的概率密度函数 f(x)\n",
    "def target_density(x):\n",
    "    if 0 < x < 1/20:\n",
    "        return 20 * np.exp(20 - 1/x) * (1 + 1/x)\n",
    "    return 0\n",
    "\n",
    "# 定义辅助分布的密度函数 g(x) (指数分布)\n",
    "def proposal_density(x):\n",
    "    return 20 * np.exp(-20 * x)  # 指数分布的密度函数\n",
    "\n",
    "# 计算常数 c (f(x) 的最大值)\n",
    "def compute_c():\n",
    "    x_values = np.linspace(0.001, 1/20, 1000)  # 避免 x = 0\n",
    "    f_values = [target_density(x) for x in x_values]\n",
    "    g_values = [proposal_density(x) for x in x_values]\n",
    "    c = max([f / g for f, g in zip(f_values, g_values)])\n",
    "    print(f\"Computed c: {c}\")  # 添加调试信息\n",
    "    return c\n",
    "\n",
    "# 拒绝采样算法\n",
    "# @timeout(seconds=2)\n",
    "def rejection_sampling(num_samples):\n",
    "    c = compute_c()  # 确定常数 c\n",
    "    samples = []\n",
    "    iterations = 0  # 添加计数器\n",
    "\n",
    "    while len(samples) < num_samples:\n",
    "        iterations += 1\n",
    "        if iterations % 1000 == 0:\n",
    "            print(f\"Iterations: {iterations}, Samples: {len(samples)}\")  # 添加调试信息\n",
    "\n",
    "        # 从辅助分布（指数分布）生成候选样本\n",
    "        x = np.random.exponential(1/20)\n",
    "        if x > 1/20:\n",
    "            continue  # 跳过超出范围的样本\n",
    "        u = np.random.uniform(0, c * proposal_density(x))  # 从 [0, c * g(x)] 中生成随机值\n",
    "\n",
    "        # 计算目标分布的密度值\n",
    "        f_x = target_density(x)\n",
    "\n",
    "        # 判断是否接受样本\n",
    "        if u <= f_x:\n",
    "            samples.append(x)\n",
    "\n",
    "    return samples\n",
    "\n",
    "# 生成样本\n",
    "num_samples = 10000\n",
    "samples = rejection_sampling(num_samples)\n",
    "\n",
    "# 绘制生成的样本分布和目标分布\n",
    "x = np.linspace(0.001, 1/20, 1000)\n",
    "y = [target_density(xi) for xi in x]\n",
    "\n",
    "plt.hist(samples, bins=50, density=True, alpha=0.6, label='Sampled Distribution')\n",
    "plt.plot(x, y, label='Target Density', color='red')\n",
    "plt.legend()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Rejection Sampling Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I choose a wrong distribution function and can not figure out a better one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good, your problem1_inversion returns a numpy array\n",
      "Good, your problem1_samples is a numpy array\n",
      "Good, your problem1_integral is a float\n",
      "Good, your problem1_interval is a tuple or list of length 2\n",
      "Generated 10 samples with 331 total iterations.\n",
      "Good, your problem1_inversion_2 returns a numpy array\n"
     ]
    }
   ],
   "source": [
    "# This cell is just to check that you got the correct formats of your answer\n",
    "import numpy as np\n",
    "try:\n",
    "    assert(isinstance(problem1_inversion(10), np.ndarray))\n",
    "except:\n",
    "    print(\"Try again. You should return a numpy array from problem1_inversion\")\n",
    "else:\n",
    "    print(\"Good, your problem1_inversion returns a numpy array\")\n",
    "    \n",
    "try:\n",
    "    assert(isinstance(problem1_samples, np.ndarray))\n",
    "except:\n",
    "    print(\"Try again. your problem1_samples is not a numpy array\")\n",
    "else:\n",
    "    print(\"Good, your problem1_samples is a numpy array\")\n",
    "    \n",
    "try:\n",
    "    assert(isinstance(problem1_integral, float))\n",
    "except:\n",
    "    print(\"Try again. your problem1_integral is not a float\")\n",
    "else:\n",
    "    print(\"Good, your problem1_integral is a float\")\n",
    "\n",
    "    \n",
    "try:\n",
    "    assert(isinstance(problem1_interval, list) or isinstance(problem1_interval,tuple)) , \"problem1_interval not a tuple or list\"\n",
    "    assert(len(problem1_interval) == 2) , \"problem1_interval does not have length 2, it should have a lower bound and an upper bound\"\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(\"Good, your problem1_interval is a tuple or list of length 2\")\n",
    "\n",
    "    \n",
    "try:\n",
    "    assert(isinstance(problem1_inversion_2(10), np.ndarray))\n",
    "except:\n",
    "    print(\"Try again. You should return a numpy array from problem1_inversion_2\")\n",
    "else:\n",
    "    print(\"Good, your problem1_inversion_2 returns a numpy array\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把数据放到合适地方再跑！！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2228, 3) (1115, 3) (2229, 3) (2228,) (1115,) (2229,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class ProportionalSpam(object):\n",
    "    def __init__(self):\n",
    "        self.coeffs = None\n",
    "        self.result = None\n",
    "    \n",
    "    # define the objective/cost/loss function we want to minimise\n",
    "    def loss(self,X,Y,coeffs):\n",
    "        \n",
    "        logits = np.dot(X, coeffs[1:]) + coeffs[0]\n",
    "        predictions = 1 / (1 + np.exp(-logits))  # 使用 sigmoid 函数得到概率\n",
    "        # 计算负对数似然损失\n",
    "        loss_value = -np.mean(Y * np.log(predictions) + (1 - Y) * np.log(1 - predictions))\n",
    "        return loss_value\n",
    "\n",
    "    def fit(self,X,Y):\n",
    "        import numpy as np\n",
    "        from scipy import optimize\n",
    "\n",
    "        #Use the f above together with an optimization method from scipy\n",
    "        #to find the coefficients of the model\n",
    "        opt_loss = lambda coeffs: self.loss(X,Y,coeffs)\n",
    "        initial_arguments = np.zeros(shape=X.shape[1]+1)\n",
    "        self.result = optimize.minimize(opt_loss, initial_arguments,method='cg')\n",
    "        self.coeffs = self.result.x\n",
    "    \n",
    "    def predict(self,X):\n",
    "        #Use the trained model to predict Y\n",
    "        if (self.coeffs is not None):\n",
    "            G = lambda x: np.exp(x)/(1+np.exp(x))\n",
    "            return np.round(10*G(np.dot(X,self.coeffs[1:])+self.coeffs[0]))/10 # This rounding is to help you with the calibration\n",
    "\n",
    "\n",
    "\n",
    "df_spam = pd.read_csv(\"data/spam.csv\",encoding='latin')\n",
    "df_spam['label'] = df_spam['v1'].apply(lambda x: 1 if x == 'spam' else 0)\n",
    "df_spam['free'] = df_spam['v2'].apply(lambda x: 1 if 'free' in x else 0)\n",
    "df_spam['prize'] = df_spam['v2'].apply(lambda x: 1 if 'prize' in x else 0)\n",
    "df_spam['win'] = df_spam['v2'].apply(lambda x: 1 if 'win' in x else 0)\n",
    "\n",
    "problem3_X = df_spam.iloc[:, 6:9].to_numpy(dtype=np.int64)\n",
    "problem3_Y = df_spam.iloc[:, 5].to_numpy(dtype=np.int64)\n",
    "\n",
    "n_samples = problem3_X.shape[0]\n",
    "\n",
    "\n",
    "# 随机打乱数据的索引\n",
    "indices = np.random.permutation(n_samples)\n",
    "\n",
    "# 计算划分点\n",
    "train_end = int(0.4 * n_samples)  # 训练集的结束位置（40%）\n",
    "calib_end = int(0.6 * n_samples)  # 校准集的结束位置（60%）\n",
    "\n",
    "# 使用切片根据划分点提取数据\n",
    "train_indices = indices[:train_end]\n",
    "calib_indices = indices[train_end:calib_end]\n",
    "test_indices = indices[calib_end:]\n",
    "\n",
    "# 划分特征和标签\n",
    "problem3_X_train = problem3_X[train_indices]\n",
    "problem3_X_calib = problem3_X[calib_indices]\n",
    "problem3_X_test = problem3_X[test_indices]\n",
    "\n",
    "problem3_Y_train = problem3_Y[train_indices]\n",
    "problem3_Y_calib = problem3_Y[calib_indices]\n",
    "problem3_Y_test = problem3_Y[test_indices]\n",
    "\n",
    "print(problem3_X_train.shape,problem3_X_calib.shape,problem3_X_test.shape,problem3_Y_train.shape,problem3_Y_calib.shape,problem3_Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "problem3_ps = ProportionalSpam()\n",
    "problem3_ps.fit(problem3_X_train, problem3_Y_train)\n",
    "\n",
    "\n",
    "problem3_Y_pred = problem3_ps.predict(problem3_X_calib).reshape(-1, 1)\n",
    "# 用决策树做校准模型\n",
    "problem3_calibrator = DecisionTreeRegressor()\n",
    "problem3_calibrator.fit(problem3_Y_pred, problem3_Y_calib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_raw = problem3_ps.predict(problem3_X_test).reshape(-1, 1)\n",
    "problem3_final_predictions = problem3_calibrator.predict(test_pred_raw)\n",
    "print(\"problem3_final_predictions:\", problem3_final_predictions[0], problem3_final_predictions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "problem3_final_predictions: 0.11026615969581749 0.11026615969581749\n"
     ]
    }
   ],
   "source": [
    "print(\"problem3_final_predictions:\", problem3_final_predictions[0], problem3_final_predictions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hoeffding_confidence_interval(value, n, confidence_level=0.99):\n",
    "    \"\"\"\n",
    "    使用 Hoeffding 不等式计算置信区间。\n",
    "    \n",
    "    参数:\n",
    "    - n: 样本数量。\n",
    "    - confidence_level: 置信水平。\n",
    "\n",
    "    返回:\n",
    "    - (lower_bound, upper_bound): 置信区间。\n",
    "    \"\"\"\n",
    "    delta = 1 - confidence_level  # 映射置信水平到 delta\n",
    "    epsilon = np.sqrt(np.log(2 / delta) / (2 * n))  # Hoeffding 界限\n",
    "    lower_bound = max(0, value - epsilon)  # 确保下界不小于 0\n",
    "    upper_bound = min(1, value + epsilon)  # 确保上界不大于 1\n",
    "    return lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "精确率的 99% 置信区间: (0.09024502771332787, 0.15919418269492694)\n"
     ]
    }
   ],
   "source": [
    "# Part 4\n",
    "# In order to compute this loss we first need to convert the predicted probabilities to a decision\n",
    "# 1) 先将概率转换成二元决策（阈值 0.5）\n",
    "predicted_labels = (problem3_final_predictions >= 0.5).astype(int)\n",
    "# 2) 计算 0-1 损失 (即分类错误的比例)\n",
    "problem2_01_loss = np.mean(predicted_labels != problem3_Y_test)\n",
    "\n",
    "# Recall the interval is given as a tuple (a,b) or a list [a,b]\n",
    "problem2_interval = hoeffding_confidence_interval(problem2_01_loss, 2229, confidence_level=0.99)\n",
    "print(f\"精确率的 99% 置信区间: {problem2_interval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your loss was correct for a test point\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import numpy as np\n",
    "    test_instance = ProportionalSpam()\n",
    "    test_loss = test_instance.loss(np.array([[1,0,1],[0,1,1]]),np.array([1,0]),np.array([1.2,0.4,0.3,0.9]))\n",
    "    assert (np.abs(test_loss-1.2828629432232497) < 1e-6)\n",
    "    print(\"Your loss was correct for a test point\")\n",
    "except:\n",
    "    print(\"Your loss was not correct on a test point\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose A for state 0, B for state 1, C for state 2, D for state 3 \\\n",
    "state numbers are also matched with index number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from functools import reduce\n",
    "from math import gcd\n",
    "from scipy.linalg import eig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PART 1转移矩阵\n",
    "P_A = np.array([[0.8, 0.2, 0.0,0.0],\n",
    "              [0.6, 0.2, 0.2,0.0],\n",
    "              [0.0, 0.4, 0.0,0.6],\n",
    "              [0.0, 0.0, 0.8,0.2]])\n",
    "\n",
    "P_B = np.array([[0.0, 0.2, 0.0,0.8],\n",
    "              [0.0, 0.0, 1.0,0.0],\n",
    "              [0.0, 1.0, 0.0,0.0],\n",
    "              [0.5, 0.0, 0.5,0.0]])\n",
    "\n",
    "P_C = np.array([[0.2, 0.3, 0.0,0.0,0.5],\n",
    "               [0.2, 0.2, 0.6,0.0,0.0],\n",
    "              [0.0, 0.4, 0.0,0.6,0.0],\n",
    "              [0.0, 0.0, 0.0,0.6,0.4],\n",
    "               [0.0,0.0,0.0,0.4,0.6]])\n",
    "\n",
    "P_D = np.array([[0.8, 0.2, 0.0,0.0],\n",
    "              [0.6, 0.2, 0.2,0.0],\n",
    "              [0.0, 0.4, 0.0,0.6],\n",
    "              [0.1, 0.0, 0.7,0.2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markov chain and Digraph have been successfully constructed.\n",
      "The size of transition matrix P_0 is: (4, 4)\n",
      "Whether it is a qualified transition matrix: The matrix is a valid transition matrix.\n",
      "Markov chain and Digraph have been successfully constructed.\n",
      "The size of transition matrix P_1 is: (4, 4)\n",
      "Whether it is a qualified transition matrix: The matrix is a valid transition matrix.\n",
      "Markov chain and Digraph have been successfully constructed.\n",
      "The size of transition matrix P_2 is: (5, 5)\n",
      "Whether it is a qualified transition matrix: The matrix is a valid transition matrix.\n",
      "Markov chain and Digraph have been successfully constructed.\n",
      "The size of transition matrix P_3 is: (4, 4)\n",
      "Whether it is a qualified transition matrix: The matrix is a valid transition matrix.\n",
      "The directed graph (Digraph) has been successfully constructed.\n",
      "Number of nodes: 4\n",
      "Number of edges: 9\n",
      "Graph edges with weights:\n",
      "Edge from 0 to 0, weight = 0.8\n",
      "Edge from 0 to 1, weight = 0.2\n",
      "Edge from 1 to 0, weight = 0.6\n",
      "Edge from 1 to 1, weight = 0.2\n",
      "Edge from 1 to 2, weight = 0.2\n",
      "Edge from 2 to 1, weight = 0.4\n",
      "Edge from 2 to 3, weight = 0.6\n",
      "Edge from 3 to 2, weight = 0.8\n",
      "Edge from 3 to 3, weight = 0.2\n",
      "The directed graph (Digraph) has been successfully constructed.\n",
      "Number of nodes: 4\n",
      "Number of edges: 6\n",
      "Graph edges with weights:\n",
      "Edge from 0 to 1, weight = 0.2\n",
      "Edge from 0 to 3, weight = 0.8\n",
      "Edge from 1 to 2, weight = 1.0\n",
      "Edge from 3 to 0, weight = 0.5\n",
      "Edge from 3 to 2, weight = 0.5\n",
      "Edge from 2 to 1, weight = 1.0\n",
      "The directed graph (Digraph) has been successfully constructed.\n",
      "Number of nodes: 5\n",
      "Number of edges: 12\n",
      "Graph edges with weights:\n",
      "Edge from 0 to 0, weight = 0.2\n",
      "Edge from 0 to 1, weight = 0.3\n",
      "Edge from 0 to 4, weight = 0.5\n",
      "Edge from 1 to 0, weight = 0.2\n",
      "Edge from 1 to 1, weight = 0.2\n",
      "Edge from 1 to 2, weight = 0.6\n",
      "Edge from 4 to 3, weight = 0.4\n",
      "Edge from 4 to 4, weight = 0.6\n",
      "Edge from 2 to 1, weight = 0.4\n",
      "Edge from 2 to 3, weight = 0.6\n",
      "Edge from 3 to 3, weight = 0.6\n",
      "Edge from 3 to 4, weight = 0.4\n",
      "The directed graph (Digraph) has been successfully constructed.\n",
      "Number of nodes: 4\n",
      "Number of edges: 10\n",
      "Graph edges with weights:\n",
      "Edge from 0 to 0, weight = 0.8\n",
      "Edge from 0 to 1, weight = 0.2\n",
      "Edge from 1 to 0, weight = 0.6\n",
      "Edge from 1 to 1, weight = 0.2\n",
      "Edge from 1 to 2, weight = 0.2\n",
      "Edge from 2 to 1, weight = 0.4\n",
      "Edge from 2 to 3, weight = 0.6\n",
      "Edge from 3 to 0, weight = 0.1\n",
      "Edge from 3 to 2, weight = 0.7\n",
      "Edge from 3 to 3, weight = 0.2\n"
     ]
    }
   ],
   "source": [
    "Ps=[P_A,P_B,P_C,P_D]\n",
    "# 验证转移矩阵的合法性\n",
    "def is_valid_transition_matrix(P):\n",
    "    # 1. 检查是否为方阵\n",
    "    if P.shape[0] != P.shape[1]:\n",
    "        return False, \"The matrix is not square.\"\n",
    "\n",
    "    # 2. 检查是否所有元素为非负数\n",
    "    if not np.all(P >= 0):\n",
    "        return False, \"The matrix contains negative elements.\"\n",
    "\n",
    "    # 3. 检查每行是否归一化为 1\n",
    "    if not np.allclose(np.sum(P, axis=1), 1):\n",
    "        return False, \"The rows do not sum to 1.\"\n",
    "\n",
    "    return True, \"The matrix is a valid transition matrix.\"\n",
    "\n",
    "# 验证转移矩阵\n",
    "is_vlid_list=[]\n",
    "for i, p in enumerate(Ps):  # 使用 enumerate 获取索引 i 和矩阵 p\n",
    "    is_valid, message = is_valid_transition_matrix(p)\n",
    "    is_vlid_list.append(is_valid)\n",
    "    \n",
    "    # 输出验证结果\n",
    "    print(f\"Markov chain and Digraph have been successfully constructed.\")\n",
    "    print(f\"The size of transition matrix P_{i} is: {p.shape}\")\n",
    "    print(f\"Whether it is a qualified transition matrix: {message}\")\n",
    "\n",
    "\n",
    "# 如果转移矩阵有效，构建有向图\n",
    "G_list=[]\n",
    "for i, p in enumerate(Ps):\n",
    "    if is_vlid_list[i]:\n",
    "        # 1. 构建有向图\n",
    "        G = nx.DiGraph()\n",
    "        \n",
    "        # 添加边和权重\n",
    "        for i in range(p.shape[0]):\n",
    "            for j in range(p.shape[1]):\n",
    "                if p[i, j] > 0:  # 仅添加非零权重的边\n",
    "                    G.add_edge(i, j, weight=p[i, j])\n",
    "        \n",
    "        # 打印构建结果\n",
    "        print(\"The directed graph (Digraph) has been successfully constructed.\")\n",
    "        print(\"Number of nodes:\", G.number_of_nodes())\n",
    "        print(\"Number of edges:\", G.number_of_edges())\n",
    "    \n",
    "        # 可视化或分析\n",
    "        print(\"Graph edges with weights:\")\n",
    "        for u, v, data in G.edges(data=True):\n",
    "            print(f\"Edge from {u} to {v}, weight = {data['weight']}\")\n",
    "        G_list.append(G)\n",
    "    else:\n",
    "        print(\"The transition matrix is not valid. Please check your input.\")\n",
    "        G_list.append(None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the Markov chain irreducible? True\n",
      "Is the Markov chain irreducible? False\n",
      "Is the Markov chain irreducible? False\n",
      "Is the Markov chain irreducible? True\n"
     ]
    }
   ],
   "source": [
    "#irreducible\n",
    "for G in G_list:\n",
    "    is_irreducible = nx.is_strongly_connected(G)\n",
    "    print(\"Is the Markov chain irreducible?\", is_irreducible)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State 0 has period: 1\n",
      "State 0 is aperiodic\n",
      "State 1 has period: 1\n",
      "State 1 is aperiodic\n",
      "State 2 has period: 1\n",
      "State 2 is aperiodic\n",
      "State 3 has period: 1\n",
      "State 3 is aperiodic\n",
      "\n",
      "\n",
      "State 0 has period: 2\n",
      "State 0 is not aperiodic\n",
      "State 1 has period: 2\n",
      "State 1 is not aperiodic\n",
      "State 2 has period: 2\n",
      "State 2 is not aperiodic\n",
      "State 3 has period: 2\n",
      "State 3 is not aperiodic\n",
      "\n",
      "\n",
      "State 0 has period: 1\n",
      "State 0 is aperiodic\n",
      "State 1 has period: 1\n",
      "State 1 is aperiodic\n",
      "State 2 has period: 1\n",
      "State 2 is aperiodic\n",
      "State 3 has period: 1\n",
      "State 3 is aperiodic\n",
      "State 4 has period: 1\n",
      "State 4 is aperiodic\n",
      "\n",
      "\n",
      "State 0 has period: 1\n",
      "State 0 is aperiodic\n",
      "State 1 has period: 1\n",
      "State 1 is aperiodic\n",
      "State 2 has period: 1\n",
      "State 2 is aperiodic\n",
      "State 3 has period: 1\n",
      "State 3 is aperiodic\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. 计算状态的周期\n",
    "# 计算状态 x 的返回时间集 T(x)\n",
    "def get_return_times(P, x):\n",
    "    n = len(P)\n",
    "    times = []\n",
    "    for t in range(1, n+1):\n",
    "        if np.linalg.matrix_power(P, t)[x, x] > 0:\n",
    "            times.append(t)\n",
    "    return times\n",
    "\n",
    "for P in Ps:\n",
    "    # 计算状态的周期\n",
    "    periods = {}\n",
    "    for x in range(len(P)):\n",
    "        T_x = get_return_times(P, x)\n",
    "        period = reduce(gcd, T_x)\n",
    "        periods[x] = period\n",
    "\n",
    "    # 输出结果\n",
    "    for state, period in periods.items():\n",
    "        print(f\"State {state} has period: {period}\")\n",
    "        if period == 1:\n",
    "            print(f\"State {state} is aperiodic\")\n",
    "        else:\n",
    "            print(f\"State {state} is not aperiodic\")\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stationary distribution: [0.25 0.25 0.25 0.25]\n",
      "\n",
      "\n",
      "Stationary distribution: [0.25 0.25 0.25 0.25]\n",
      "\n",
      "\n",
      "Stationary distribution: [0.2 0.2 0.2 0.2 0.2]\n",
      "\n",
      "\n",
      "Stationary distribution: [0.25 0.25 0.25 0.25]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#stationary distribution\n",
    "# 4. 平稳分布 (stationary distribution)\n",
    "stt_st=[]\n",
    "for P in Ps:\n",
    "    w, v = eig(P.T, left=True, right=False)\n",
    "    stationary = np.real(v[:, np.isclose(w, 1)])\n",
    "    stationary = stationary / stationary.sum()\n",
    "    stt_st.append(stationary)\n",
    "    print(\"Stationary distribution:\", stationary.ravel())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the Markov chain reversible? False\n",
      "Is the Markov chain reversible? False\n",
      "Is the Markov chain reversible? False\n",
      "Is the Markov chain reversible? False\n"
     ]
    }
   ],
   "source": [
    "#reversible\n",
    "for stationary in stt_st:\n",
    "    # 计算平稳分布 π\n",
    "    stationary = stationary.ravel()  # 将平稳分布从二维转换为一维\n",
    "    is_reversible = True  # 初始假设是可逆的\n",
    "    \n",
    "    # 遍历所有状态对 (i, j)\n",
    "    for i in range(len(P)):\n",
    "        for j in range(len(P)):\n",
    "            if not np.isclose(stationary[i] * P[i, j], stationary[j] * P[j, i]):\n",
    "                is_reversible = False\n",
    "                break\n",
    "        if not is_reversible:\n",
    "            break\n",
    "    \n",
    "    print(\"Is the Markov chain reversible?\", is_reversible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
